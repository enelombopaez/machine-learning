{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fundamentos de *Machine Learning*\n",
    "\n",
    "En este notebook se revisarán los conceptos de:\n",
    "\n",
    "1. Notación\n",
    "2. Vecinos más próximos\n",
    "3. Repaso de Pandas\n",
    "4. Evaluación del modelo: entrenamiento y test\n",
    "5. Selección del modelo: validación cruzada\n",
    "6. Conceptos fundamentales de ML\n",
    "  1. Compromiso sesgo-varianza\n",
    "  2. Curvas de aprendizaje\n",
    "\n",
    "Primero cargamos librerías y funciones necesarias, incluyendo las del módulo `utils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_decision_boundary, poly_linear_regression, CM_BRIGHT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Notación\n",
    "\n",
    "Vamos a importar la librería principal de este módulo, scikit-learn. Habitualmente se importa como `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos echar un vistazo a los [datasets](http://scikit-learn.org/stable/datasets) de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.1: Sobre el conjunto de datos anterior, el dataset de diabetes, vamos a calcular los siguientes valores:\n",
    "</div>\n",
    "\n",
    "* $N$: número de muestras\n",
    "* $d$: dimensionalidad del espacio de entrada\n",
    "* $\\mathbf{x}^{(10)}$: muestra $i=10$\n",
    "* $\\mathbf{x}_1$: característica/variable/*feature* $1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para resolver el problema, vamos a seguir una serie de pasos.\n",
    "# Lo primero es saber a qué nos enfrentamos: qué son x e y?\n",
    "\n",
    "# ... código para analizar qué tipo de datos son X e y\n",
    "\n",
    "# .... código para saber el tamaño (o la forma) de X e y\n",
    "\n",
    "# Sabiendo la forma de X deberíamos ser capaces de determinar el número de muestras y la dimensionalidad\n",
    "\n",
    "n = ...\n",
    "d = ...\n",
    "\n",
    "print(f'El numero de muestras es {n} y la dimensionalidad es {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En cuanto a la muestra número 10, debemos recordar que Python es zero-indexed\n",
    "\n",
    "# ... código para extraer el décimo elemento en la primera dimensión de X (es decir, las filas)\n",
    "\n",
    "x_10 = ...\n",
    "print(x_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la primera característica, también debemos recordar que Python es zero-indexed\n",
    "\n",
    "# ... código para extraer el primer elemento en la segunda dimensión de X (es decir, las columnas)\n",
    "\n",
    "x1 = ...\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.2: ¿Es un problema de clasificación o de regresión? ¿Por qué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cómo podríamos determinar si el problema es de regresión o clasificación? ¿Qué es lo que diferencia a uno de otro?\n",
    "\n",
    "# ... código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vecinos más próximos\n",
    "\n",
    "En este notebook vamos a trabajar con el algoritmo de KNN en distintos problemas de **clasificación**.\n",
    "\n",
    "### 2.1. Medida de las prestaciones de un clasificador\n",
    "\n",
    "Por clasificador entendemos un algoritmo que, a partir de un conjunto de muestras/observaciones de entrenamiento, es capaz de identificar a qué clase (categoría) pertenece una nueva observación.\n",
    "\n",
    "Una métrica de calidad que podemos usar para medir las prestaciones de un clasificador es el **error de clasificación**\n",
    "\n",
    "$$\\textrm{Error} = \\frac{\\textrm{núm de muestras mal clasificadas}}{\\textrm{núm de muestras total del problema}}$$\n",
    "\n",
    "* Ejemplo: problema de clasificación con dos clases $y\\in{0,1}$\n",
    "    * Etiquetas reales (*y_true*) = $[1,0,0,1,0]$\n",
    "    * Etiquetas predichas (*y_pred*) = $[0,0,1,1,0]$\n",
    "    \n",
    "    * En este caso: $$\\textrm{Error} = \\frac{\\textrm{núm de muestras mal clasificadas} = 2}{\\textrm{núm de muestras total del problema} = 5} = \\frac{2}{5} = 0.4$$\n",
    "\n",
    "Así, el error de clasificación será un número entre 0 y 1, tal que:\n",
    "\n",
    "* $\\textrm{Error} = 0$ es el mejor valor posible (no me equivoco nada)\n",
    "* $\\textrm{Error} = 1$ es el peor valor posible (me equivoco en todas las muestras). Nota: si me equivoco en la clasificación de todas las muestras, entonces puedo interpretar que el clasificador es bueno, pero que tengo que hacer justo lo contrario de lo que me dice. El peor valor de error sería por tanto $0.5$, en el que la incertidumbre es mayor. \n",
    "\n",
    "Normalmente no se utiliza el error, sino su complementario, la exactitud o [**accuracy**](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) (Acc):\n",
    "\n",
    "$$\\textrm{Acc} = 1 - \\textrm{Error}$$\n",
    "\n",
    "y entonces:\n",
    "\n",
    "* $\\textrm{Acc} = 1$ es el mejor valor posible (no me equivoco nada)\n",
    "* $\\textrm{Acc} = 0$ es el peor valor posible (me equivoco en todas las muestras)\n",
    "\n",
    "### 2.2 Ejemplos\n",
    "\n",
    "Para analizar el comportamiento del algoritmo de K-NN, utilizaremos tres ejemplos sencillos, como mostraremos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo1\n",
    "ejemplo1 = pd.read_csv(\"./data/ex2data1.txt\", sep=\",\", header=None, names=['x1', 'x2', 'label'])\n",
    "ejemplo1.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qué tipo de datos es `ejemplo1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Pequeño desvío: repaso de Pandas\n",
    "\n",
    "A no ser que alguien me haya engañado, habéis trabajado ya con Pandas. Sin embargo, lo normal es que no os acordéis de nada, así que vamos a hacer un pequeño repaso de las funciones más habituales. No toméis esto como un estudio exhaustivo, ni mucho menos; pero grosso modo os servirá para este módulo.\n",
    "\n",
    "Vamos a ver los siguientes métodos:\n",
    "\n",
    "- `.describe()`, que proporciona un pequeño análisis estadístico. El parámetro `include=all` permite añadir variables categóricas\n",
    "- `.shape`\n",
    "- `.head()`\n",
    "- `.tail()`\n",
    "- `.dtypes`\n",
    "- Análisis de valores nulos con `.isnull()` e `.isnull().any()`\n",
    "- Eliminación de columnas con `.drop(c1, axis=1)`\n",
    "- Cómo acceder a los índices internos, con `.index` y `.index.values`\n",
    "- Cómo acceder a un elemento determinado en base a su índice, con `.iloc[[i1, i2, i3, ...]]`\n",
    "- Cómo construir un nuevo dataframe filtrando el anterior, con `df_filtered = df[condición]`\n",
    "- Cómo construir un nuevo dataframe filtrando el anterior bajo condición múltiple, con `df_filtered = df[(condición 1) & (condición 2)]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez estudiado el dataframe, podemos representar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ejemplo1['x1'], ejemplo1['x2'], c=ejemplo1['label'], cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dice que este problema es **linealmente separable**, porque podemos trazar una recta para separar las dos clases (representadas en distintos colores, rojo y azul).\n",
    "* En el plano bidimensional: recta\n",
    "* En un espacio d-dimensional: hiperplano\n",
    "\n",
    "Nota: No es linealmente separable puesto que la separación no es perfecta. Pero es _casi_ linealmente separable, aceptamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo2\n",
    "ejemplo2 = pd.read_csv(\"./data/ex2data2.txt\", sep=\",\", header=None, names=['x1', 'x2', 'label'])\n",
    "\n",
    "plt.scatter(ejemplo2['x1'], ejemplo2['x2'], c=ejemplo2['label'], cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dice que este problema es **no linealmente separable**, porque no podemos trazar una recta para separar las dos clase (representadas en distintos colores, rojo y azul)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo 3: Problema XOR \n",
    "np.random.seed(0)\n",
    "\n",
    "# -- parameters\n",
    "N     = 800\n",
    "mu    = 1.5      # Cambia este valor\n",
    "sigma = 1      # Cambia este valor\n",
    "\n",
    "# variables auxiliares\n",
    "unos = np.ones(int(N/4))\n",
    "random4 = sigma*np.random.randn(int(N/4),1)\n",
    "random2 = sigma*np.random.randn(int(N/2),1)\n",
    "\n",
    "# -- features\n",
    "y3 = np.concatenate([-1*unos, unos, unos, -1*unos]) \n",
    "X1 = np.concatenate([-mu + random4, mu + random4, -mu + random4, mu + random4])\n",
    "X2 = np.concatenate([+mu + random2, -mu + random2])\n",
    "X3 = np.hstack((X1,X2))\n",
    "\n",
    "plt.scatter(X3[:,0], X3[:,1], c=y3, cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el caso anterior, este ejemplo tampoco es linealmente separable, y se conoce como problema XOR. La ventaja del problema XOR es que conocemos cuál es la frontera de separación óptima a priori:\n",
    "\n",
    "- Clase 1, color azul: $x_1,x_2 > 0$, y $ x_1,x_2 < 0$ (cuadrantes 1 y 3)\n",
    "- Clase 2, color rojo: $x_1 < 0,  x_2 > 0$, y $x_1 > 0,  x_2 < 0$ (cuadrantes 2 y 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Entrenar el modelo \n",
    "\n",
    "Vamos a entrenar un [modelo K-NN](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) para los distintos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Ejemplo 1\n",
    "# preparamos los datos\n",
    "data1 = ejemplo1.values\n",
    "print(f'El tipo de datos es {type(data1)}')\n",
    "X1 = data1[:, 0:2]\n",
    "y1 = data1[:, -1]\n",
    "\n",
    "# creamos el modelo y ajustamos\n",
    "knnModel = KNeighborsClassifier(n_neighbors=1).fit(X1, y1)\n",
    "\n",
    "plot_decision_boundary(X1, y1, knnModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTA: Fijaos que para entrenar utilizamos `.fit()`. Esto entrena el modelo con todos los datos disponibles, lo que se conoce como batch learning; la alternativa es entrenar con pequeños conjuntos de datos nuevos a medida que van llegando: online learning. La inmensa mayoría de algoritmos en scikit learn están diseñados para batch learning, pero algunos tienen implementada una opción para entrenamientos parciales, `partial_fit`. Para más info, echad un ojo a [la documentación](https://scikit-learn.org/0.15/modules/scaling_strategies.html#incremental-learning).\n",
    "\n",
    "> Más info sobre batch, mini-batch y online learning [aquí](https://www.kaggle.com/code/residentmario/full-batch-mini-batch-and-online-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Número de vecinos**\n",
    "\n",
    "Podemos modificar el número de vecinos $k$ del algoritmo k-nn implementado en scikit-learn mediante el parámetro *n_neighbors*. Por defecto, [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) toma *n_neighbors* $=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.3: Varía el valor de <b>n_neighbors</b>, ¿qué sucede ahora?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.4: Aplica el algoritmo K-NN sobre los ejemplos 2 y 3. ¿Qué sucedería si aplicamos sobre estos ejemplos un algoritmo de <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">regresión logística</a>? ¿Qué pasa si variamos el número de vecinos?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ... código para preparar los datos\n",
    "X2 = ...\n",
    "y2 = ...\n",
    "\n",
    "# ... código para crear el modelo y entrenar\n",
    "knnModel2 = ...\n",
    "\n",
    "plot_decision_boundary(X2, y2, knnModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# .... código para crear el modelo y entrenar\n",
    "lrModel = ...\n",
    "plot_decision_boundary(X2, y2, lrModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No funciona bien, ¿no? ¿Qué creéis que está pasando?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ... código para preparar los datos\n",
    "X3 = ...\n",
    "y3 = ...\n",
    "\n",
    "# ... código para crear el modelo y entrenar\n",
    "knnModel3 = ...\n",
    "\n",
    "plot_decision_boundary(X3, y3, knnModel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# .... código para crear el modelo y entrenar\n",
    "lrModel3 = ...\n",
    "plot_decision_boundary(X3, y3, lrModel3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que las mejores prestaciones se obtienen cuando *n_neighbors=1*, ¿tiene sentido? ¿Estamos midiendo correctamente las prestaciones de este clasificador?\n",
    "\n",
    "# 3. Evaluación del modelo: entrenamiento y test\n",
    "\n",
    "La respuesta es claramente no. Para poder saber cómo de bien se comporta un algoritmo de machine learning, hemos de medir su capacidad de [generalización](https://en.wikipedia.org/wiki/Generalization_error), esto es, las prestaciones en muestras no vistas previamente por el clasificador. Para ello, dividimos el conjunto de entrenamiento en dos partes, entrenamiento y test, teniendo en cuenta que:\n",
    "\n",
    "![](./figuras/train_test_set_2d_classification.png)\n",
    "\n",
    "* Utilizamos aproximadamente un 75-80% de las muestras para entrenamiento y un 25-20% para el test (cuidado! depende del tamaño del dataset; si es muy grande, el conjunto de test puede ser un porcentaje menor)\n",
    "* Ambos conjuntos han de representar la población con la misma estadística: \n",
    "    * Randomizar, esto es, reordenar para evitar orden en las muestras. (cuidado series temporales)\n",
    "    * Estratificar con respecto a una variable (normalmente la variable target), para mantener la proporción de la varible target en los conjuntos train/test.\n",
    "\n",
    "sklearn nos proporciona una [función](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) para dividir nuestros datos. \n",
    "\n",
    "Vamos a probar con el primer ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "print(type(X_train))\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "plot_decision_boundary(X_test, y_test, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.5: Sobre la celda anterior, varía el valor de <b>n_neighbors</b>. ¿Para qué valor se obtienen ahora las mejores prestaciones? ¿Qué sucede si eliminamos <b>random_state = 0</b> y ejecutamos varias veces la misma celda para un valor de <b>n_neighbors</b> fijo? ¿Obtenemos las mismas prestaciones?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.6: Calcula las prestaciones del algoritmo K-NN para los ejemplos 2 y 3. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ... código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ... código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.7: Vamos a realizar un análisis del parámetro de estratificación, para ver el efecto que tiene en los datos \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una forma de estudiarlo\n",
    "ejemplo1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra forma de estudiarlo\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora: cómo haríais el análisis completo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.8 (AVANZADO): Representa las prestaciones del algoritmo K-NN en entrenamiento y test para distintos valores de <b>n_neighbors</b> (entre 1 y 15), utilizando el ejemplo 3. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "# inicializamos\n",
    "neighbors = range(1,15)\n",
    "acc_train = []\n",
    "acc_test  = []\n",
    "\n",
    "for n in neighbors:\n",
    "    \n",
    "    # ... código aquí\n",
    "    # pista: lo único que hay que hacer es instanciar el modelo,\n",
    "    # definiendo correctamente el parámetro del número de vecinos,\n",
    "    # y luego hacer `.fit()` sobre los datos de train\n",
    "    \n",
    "    acc_train.append(knn.score(X_train, y_train))\n",
    "    acc_test.append(knn.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "plt.plot(neighbors,acc_train,'b',label='train')\n",
    "plt.plot(neighbors,acc_test,'r',label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('ACC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El número de vecinos que escojamos afecta significativamente a las prestaciones del algoritmo. Este parámetro es un compromiso entre los errores que cometemos (*accuracy*) y la complejidad del modelo (frontera de separación). \n",
    "\n",
    "- Cuanto menor es el número de vecinos, **más compleja** es la frontera de separación, y por tanto mayor será el sobreajuste. Potencialmente empeorará la *accuracy*.\n",
    "- Cuanto mayor es el número de vecinos, **menos compleja** es la frontera de separación y por tanto menor será el sobreajuste. Potencialmente mejorará la *accuracy*.\n",
    "\n",
    "## 3.1 Conclusiones\n",
    "\n",
    "1. Si las muestras de entrenamiento son escasas (ejemplo 1), el error en test puede ser muy variable , dependiendo de las muestras incluidas en el conjunto de entrenamiento y el conjunto de test.\n",
    "\n",
    "2. Las prestaciones (en test), dependen del número de vecinos que determinan la complejidad de la frontera de separación.\n",
    "\n",
    "Teniendo en cuenta 1 y 2, ¿cómo puedo escoger el valor óptimo de *n_neighbors*?\n",
    "\n",
    "Vamos a volver a teoría un momentito y lo vemos allí.\n",
    "\n",
    "\n",
    "# 4. Selección del modelo: validación cruzada\n",
    "\n",
    "La validación cruzada (o cross-validation) consiste en subdivir el conjunto de entrenamiento en $K$ partes iguales, de tal forma que se utilizan $K-1$ para entrenar (ajustar el modelo) y el bloque $k$ restante para evaluar las prestaciones en función de los parámetros libres. Este proceso se repite $K$ veces (hasta que se barren todos los bloques) y los resultados se promedian.\n",
    "\n",
    "Por suerte, no es necesario programar estas subdivisiones, porque scikit-learn tiene un clase que realiza este trabajo por nosotros. Puedes consultarlo [aquí](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).\n",
    "\n",
    "Vamos a buscar el valor óptimo del número de vecinos utilizando una estrategia 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# recordemos que este es nuestro conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0, stratify=y3)\n",
    "\n",
    "nFolds = 5 #scikit-learn los llama splits\n",
    "kf  = StratifiedKFold(n_splits = nFolds, shuffle = True, random_state=0)\n",
    "\n",
    "nVecinos = range(1,16) # [1-15]\n",
    "\n",
    "# inicializamos una matriz de errores, para cada valor de n_neighbors y cada iteración del algoritmo de cross-validation\n",
    "# - tantas filas como número de folds\n",
    "# - tantas columnas como valores de alphaVector\n",
    "accMatriz = np.zeros((nFolds,len(nVecinos))) \n",
    "\n",
    "j = 0 # inicializamos contador de columnas\n",
    "for n in nVecinos:\n",
    "       \n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    \n",
    "    i = 0 # inicializamos contador de filas\n",
    "    for idxTrain, idxVal in kf.split(X_train,y_train):\n",
    "      \n",
    "        Xt = X_train[idxTrain,:]\n",
    "        yt = y_train[idxTrain]\n",
    "        Xv = X_train[idxVal,:]\n",
    "        yv = y_train[idxVal]\n",
    "        \n",
    "        knn.fit(Xt,yt)\n",
    "        accMatriz[i,j] = knn.score(Xv, yv) \n",
    "        \n",
    "        i+=1\n",
    "    j+=1\n",
    "\n",
    "accVector = np.mean(accMatriz,axis=0)\n",
    "accStd = np.std(accMatriz,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el valor óptimo\n",
    "idx = np.argmax(accVector)\n",
    "nOpt = nVecinos[idx]\n",
    "\n",
    "plt.plot(nVecinos,accVector,'-o')\n",
    "plt.plot(nVecinos[idx],accVector[idx],'rs')\n",
    "plt.title('El número óptimo de vecinos es: %d' % nOpt)\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representemos ahora la gráfica anterior con la variación (desviación estándar) de la *accuracy* en cada *fold*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nVecinos,accVector,'-o')\n",
    "plt.plot(nVecinos[idx],accVector[idx],'rs')\n",
    "plt.errorbar(nVecinos, accVector, yerr=accStd, ecolor='g')\n",
    "plt.title('El número óptimo de vecinos es: %d' % nOpt)\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damos las prestaciones reales del modelo (en test)\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "print(\"accuracy: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior se puede reducir drásticamente si utilizamos [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Pido perdón por el susto. Aún así, a veces será necesario implementar validación cruzada con KFold si necesitamos más control sobre el proceso, así que tampoco está mal verlo en detalle.\n",
    "\n",
    "El código de la siguiente celda es equivalente al de las cuatro celdas anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "param_grid = {'n_neighbors':  np.arange(1, 16, 1)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), scoring= 'accuracy', param_grid=param_grid, cv = 5, verbose=1).fit(X_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score']) #¡cuidado, lo llaman test cuando es validación!\n",
    "stdvalues = np.array(grid.cv_results_['std_test_score'])\n",
    "plt.plot(np.arange(1, 16, 1),scores,'-o')\n",
    "plt.errorbar(nVecinos, scores, yerr=stdvalues, ecolor='g')\n",
    "plt.xlabel('# vecinos')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"acc (test): {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ¿Cómo elegimos el algoritmo adecuado?\n",
    "\n",
    "No hay *free lunch*, ningún método/algoritmo es mejor que otro para todos los problemas (conjuntos de datos). Para entender si el algoritmo adecuado se comporta adecuadamente, hay que tener en cuenta:\n",
    "\n",
    "- Ruido en los datos (error irreducible)\n",
    "- Número de ejemplos disponibles\n",
    "- Número de características (dimensionalidad del problema)\n",
    "\n",
    "## 5.1 Compromiso sesgo-varianza\n",
    "\n",
    "Supongamos que tenemos un proceso $y = g(x) + \\epsilon$, donde $\\epsilon$ representa una fuente de error irreducible (ruido en los datos). Del proceso $y$, tenemos información de un conjunto de muestras  $D = \\{x^{(i)},y^{(i)}\\}$, con $i=1,\\ldots,N$. \n",
    "\n",
    "A partir de estos datos $D$, buscamos encontrar la función $f_{\\omega}(x)$ que *mejor se ajuste* a la verdadera función $g(x)$, utilizando un algoritmo de *machine learning*. Por mejor ajuste se entiende que se quiere medir el error cuadrático medio $\\left(y - f_{\\omega}(x)\\right)^2$, tanto para el conjunto $D$, como para cualquier muestra no contenida en $D$ (capacidad de generalización). \n",
    "\n",
    "Dado que $y$ es un proceso que contiene ruido, es difícil que podamos ajustar $f_{\\omega}(x)$ a $g(x)$ de forma perfecta. Se puede demostrar que, en promedio, el error que se comete para cualquier valor de $x\\notin D$ (error de generalización), se descompone en:\n",
    "\n",
    "$$ \\textrm{error}(x) = E\\Big[\\big(y - f_{\\omega}(x)\\big)^2\\Big] = \\textrm{Bias}\\big[f_{\\omega}(x)\\big]^2 + \\textrm{Var}\\big[f_{\\omega}(x)\\big] + \\sigma^2 $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $\\textrm{Bias}\\big[f_{\\omega}(x)\\big]^2 = E\\Big[f_{\\omega}(x)\\Big]^2 - g(x)$ representa el error asociado a la simplicidad del modelo.\n",
    "* $\\textrm{Var}\\big[f_{\\omega}(x)\\big]$ representa la variabilidad del modelo frente a distintos conjuntos de entrenamiento. Pequeños cambios en el conjunto de entrenamiento pueden producir grandes errores.\n",
    "* $\\sigma^2$ es una cota al error mínimo que puedo alcanzar. \n",
    "\n",
    "Por tanto, el objetivo es buscar un algoritmo que proporcione mínimo sesgo y mínima varianza.\n",
    "\n",
    "### 5.1.1 Ejemplo\n",
    "\n",
    "Veamos con un ejemplo. Supongamos que $y = g(x) + \\epsilon$, donde:\n",
    "\n",
    "* $g(x) = \\cos{(1.5\\pi x})$, $x \\in [0,1]$\n",
    "* $\\epsilon \\sim N(0,\\sigma^2)$, $\\sigma = 0.2$\n",
    "* Disponemos del conjunto de datos $D = \\{x^{(i)},y^{(i)}\\}$, con $i=1,\\ldots,N$. \n",
    "\n",
    "Queremos estimar $g(x)$ a partir del conjunto de datos $D$ disponible. Para ello, vamos a utilizar tres funciones:\n",
    "\n",
    "* Regresión lineal orden 1: modelo **sencillo** $$f^1_{\\omega}(x) = \\omega_0 + \\omega_1 x$$ \n",
    "* Regresión lineal orden 4: modelo **intermedio** $$f^4_{\\omega}(x) = \\omega_0 + \\omega_1 x + \\omega_2 x^2 + \\omega_3 x^3 + \\omega_4 x^4$$ \n",
    "* regresión lineal orden 7: modelo **flexible** (complejo) $$f^{7}_{\\omega}(x) = \\omega_0 + \\sum_{j=1}^{7}\\omega_j x^j$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 10\n",
    "N_test  = 100\n",
    "\n",
    "# función verdadera g(x)\n",
    "x = np.linspace(0,1,N_test)\n",
    "g_x = np.cos(1.5*np.pi*x)\n",
    "\n",
    "# proceso y\n",
    "np.random.seed(0) # para asegurar reproducibilidad\n",
    "epsilon = np.random.randn(N_test) * 0.2\n",
    "y = g_x + epsilon\n",
    "\n",
    "# Datos: D = {x_i,y_i}, obtenemos una muestra\n",
    "idx = np.random.randint(0,N_test,N_train)\n",
    "x_i = x[idx]\n",
    "y_i = y[idx]\n",
    "\n",
    "# Representamos la función g(x), y el conjunto de datos x_i, y_i\n",
    "plt.plot(x_i, y_i, 'b.', label='Training set')\n",
    "plt.plot(x, g_x, 'r', label='Funcion objetivo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación representamos la salida obtenida y el error cometido para las tres funciones definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecute esta celda\n",
    "grado_polinomio = [1,4,7]\n",
    "\n",
    "#idx = np.random.randint(0,N_test,N_train)\n",
    "#x_i = x[idx]\n",
    "#y_i = y[idx]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for j,d in enumerate(grado_polinomio):\n",
    "    \n",
    "    f_k, mse, _ = poly_linear_regression(x_i,y_i,x,y,d)\n",
    "    \n",
    "    ax = plt.subplot(1, 3, j+1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "    plt.plot(x,g_x,'r',label='$g(x)$')\n",
    "    plt.plot(x_i,y_i,'b.',label='muestras')\n",
    "    plt.plot(x,f_k,'g',label='$f_w(x)$')\n",
    "    plt.title('Grado: %i\\nMSE:%.2f'%(d,mse))\n",
    "    plt.legend()\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede comprobar que el modelo de orden 7 se **sobreajusta** a las muestras de entrenamiento (la función pasa por los puntos de entrenamiento), y por tanto su capacidad de generalización es muy limitada.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 1.9: Descomenta las líneas de código y vuelva a ejecutar la celda, ¿qué resultado obtienes ahora?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, para analizar el sesgo y la varianza de los modelos anteriores, tenemos que calcular sus prestaciones para distintos conjuntos de entrenamiento, y posteriormente calcular su media y su varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "N = 10\n",
    "grado_polinomio = [1,4,7]\n",
    "Nrepeticiones = 20\n",
    "\n",
    "# inicializamos\n",
    "mse  = np.zeros((len(grado_polinomio),Nrepeticiones))\n",
    "f_w  = np.zeros((Nrepeticiones,N_test,len(grado_polinomio)))\n",
    "np.random.seed(0)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for k in range(Nrepeticiones):\n",
    "    \n",
    "    y = g_x + np.random.randn(N_test) * 0.2\n",
    "    \n",
    "    # Obtenemos las muestras de un nuevo conjunto de entrenamiento\n",
    "    idx = np.random.randint(0,N_test,N_train)\n",
    "    x_i = x[idx]\n",
    "    y_i = y[idx]\n",
    "    \n",
    "    for j,d in enumerate(grado_polinomio):\n",
    "\n",
    "        f_k, mse[j,k], _ = poly_linear_regression(x_i,y_i,x,y,d)\n",
    "        f_w[k,:,j] = f_k\n",
    "\n",
    "        ax = plt.subplot(1, 3, j+1)\n",
    "        plt.plot(x_i,y_i,'b.',alpha=0.1)\n",
    "        plt.plot(x,f_k,'g',alpha=0.1)\n",
    "        \n",
    "\n",
    "for j,d in enumerate(grado_polinomio):\n",
    "    ax1 = plt.subplot(1, 3, j+1)\n",
    "    f_k = np.mean(f_w[:,:,j],axis=0)\n",
    "    \n",
    "    bias = g_x - f_k\n",
    "    var = np.var(f_w[:,:,j],axis=0)\n",
    "        \n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "    plt.plot(x,g_x,'r')\n",
    "    plt.plot(x,f_k,'g',linewidth=2)\n",
    "    plt.title('Grado: %i\\nMSE: %.2f +/- %.2f\\nBIAS: %.2f VAR: %.2f'%(d,\n",
    "                                                                     np.mean(mse[j,:]),\n",
    "                                                                     np.std(mse[j,:]),\n",
    "                                                                     np.mean(bias**2),\n",
    "                                                                     np.mean(var)))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.xlim((0, 1))\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado anterior nos indica que modelos muy complejos tienden a sobreajustarse a los datos (alta varianza), mientras que modelos muy sencillos (alto sesgo), no consiguen aproximarse adecuadamente. Así, el compromiso buscar un algoritmo que tenga mínimo sesgo y mínima varianza.\n",
    "\n",
    "Así: \n",
    "\n",
    "* Para reducir el sesgo, se necesitan modelos más complejos\n",
    "* Para reducir la varianza, se necesita reducir la complejidad. Una opción es aumentar el número de muestras de entrenamiento. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a representar el error cuadrático medio (entrenamiento y test) para distintos niveles de complejidad del algoritmo de regresión lineal (distintos grados del polinomio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "grado_polinomio = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "Nrepeticiones = 100\n",
    "\n",
    "# inicializamos\n",
    "mse_test  = np.zeros((len(grado_polinomio),Nrepeticiones))\n",
    "mse_train  = np.zeros((len(grado_polinomio),Nrepeticiones))\n",
    "np.random.seed(0)\n",
    "\n",
    "for k in range(Nrepeticiones):\n",
    "    \n",
    "    y = g_x + np.random.randn(N_test) * 1\n",
    "    \n",
    "    idx = np.random.randint(0,N_test,N)\n",
    "    x_i = x[idx]\n",
    "    y_i = y[idx]\n",
    "    \n",
    "    for j,d in enumerate(grado_polinomio):\n",
    "\n",
    "        _, mse_test[j,k], mse_train[j,k] = poly_linear_regression(x_i,y_i,x,y,d)\n",
    "\n",
    "# Representamos\n",
    "plt.plot(grado_polinomio, np.mean(mse_train, axis=1), 'b', label='Error training')\n",
    "plt.plot(grado_polinomio, np.mean(mse_test, axis=1), 'r', label='Error test')\n",
    "plt.ylim(0, 5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberías obtener algo como:\n",
    "\n",
    "![](figuras/entrenamiento_test_complejidad.png)\n",
    "\n",
    "Fuente: *The Elements of Statistical Learning*\n",
    "\n",
    "Por tanto, examinando la diferencia en las prestaciones entre el conjunto de entrenamiento/validación y test, puedes saber si estás en alguna de las siguientes situaciones:\n",
    "\n",
    "* **Alto sesgo**: error de entrenamiento/validación y error en test similar, pero muy alto. Cuando esto sucede podemos\n",
    "    * Aumentar el número de variables / características\n",
    "    * Aumentar el grado del polinomio (mayor complejidad)\n",
    "* **Alta varianza**: gran diferencia entre error de entrenamiento/validación y test con un error de entrenamiento pequeño\n",
    "    * Aumentar el número de muestras de entrenamiento\n",
    "    * Reducir el número de variables / características\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Número de ejemplos disponibles\n",
    "\n",
    "De la discusión anterior podemos pensar que cuando tratamos con un problema muy complejo, utilizar más muestras de entrenamiento siempre nos va a ayudar, así que deberíamos dedicar muchos esfuerzo en conseguir muchos ejemplos. Pues bien, esto no es del todo cierto, y para ello podemos representar las curvas de aprendizaje o *learning curves*, las cuales representan la evolución de las prestaciones de un algoritmo supervisado (entrenamiento/validación y test) frente al número de muestras utilizadas. \n",
    "\n",
    "Estas curvas tienen un aspecto como\n",
    "\n",
    "![](figuras/learning_curves.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO: ¿Podrías decir cuál de las curvas anteriores se corresponde con un problema de alto sesgo/varianza?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Dimensionalidad\n",
    "\n",
    "Hace referencia al número de características que podemos utilizar en un problema de aprendizaje automático. Hay que tener en cuenta el principio de la [Maldición de la dimensionalidad](https://en.wikipedia.org/wiki/Curse_of_dimensionality).\n",
    "\n",
    "Este principio indica que a medida que el número de variables o características aumenta, el número de muestras de entrenamiento que necesitamos para generalizar correctamente aumenta exponencialmente.\n",
    "\n",
    "Así, también se puede controlar la complejidad (varianza), modificando el número de características. Técnicas como selección de características, resultan pues de utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "1. Capítulo 2. An Introduction to Statistical Learning. \n",
    "2. [Bias–variance tradeoff](https://en.wikipedia.org/wiki/Bias–variance_tradeoff)\n",
    "3. [Underfitting and overfitting, scikit learn docs](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
