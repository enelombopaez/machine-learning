{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión\n",
    "\n",
    "Vamos a analizar el funcionamiento de los [árboles de decisión](http://scikit-learn.org/stable/modules/tree.html) mediante ejemplos sencillos. Los contenidos son:\n",
    "\n",
    "1. Árboles de clasificación sobre ejemplos sintéticos\n",
    "2. Árboles de clasificación sobre ejemplo realista\n",
    "3. Árboles de regresión\n",
    "\n",
    "Primero cargamos librerías y funciones necesarias, incluyendo las del módulo `utils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_decision_boundary, CM_BRIGHT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Árboles de clasificación sobre ejemplos sintéticos\n",
    "\n",
    "Trabajaremos con los mismos ejemplos de los notebooks anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo1\n",
    "ejemplo1 = pd.read_csv(\"./data/ex2data1.txt\", sep=\",\", header=None, names=['x1', 'x2','label'])\n",
    "\n",
    "# ejemplo2\n",
    "ejemplo2 = pd.read_csv(\"./data/ex2data2.txt\", sep=\",\", header=None, names=['x1', 'x2','label'])\n",
    "\n",
    "# ejemplo 3: Problema XOR \n",
    "np.random.seed(0)\n",
    "\n",
    "# -- parameters\n",
    "N     = 800\n",
    "mu    = 1.5      # Cambia este valor\n",
    "sigma = 1      # Cambia este valor\n",
    "\n",
    "# variables auxiliares\n",
    "unos = np.ones(int(N/4))\n",
    "random4 = sigma*np.random.randn(int(N/4),1)\n",
    "random2 = sigma*np.random.randn(int(N/2),1)\n",
    "\n",
    "# -- features\n",
    "y3 = np.concatenate([-1*unos,       unos,          unos,         -1*unos]) \n",
    "X1 = np.concatenate([-mu + random4, mu + random4, -mu + random4, mu + random4])\n",
    "X2 = np.concatenate([+mu + random2,               -mu + random2])\n",
    "X3 = np.hstack((X1,X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(ejemplo1['x1'], ejemplo1['x2'], c=ejemplo1['label'], cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.title('Ejemplo 1')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(ejemplo2['x1'], ejemplo2['x2'], c=ejemplo2['label'], cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.title('Ejemplo 2')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(X3[:,0], X3[:,1], c=y3, cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.title('Ejemplo 3')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a entrenar un árbol de decisión sobre el ejemplo 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# preparamos los datos\n",
    "data1 = ejemplo1.values\n",
    "X1 = data1[:, 0:2]\n",
    "y1 = data1[:, -1]\n",
    "\n",
    "# creamos el modelo y ajustamos\n",
    "treeModel1 = DecisionTreeClassifier().fit(X1, y1)\n",
    "\n",
    "plot_decision_boundary(X1, y1, treeModel1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 4.1: Entrena un árbol de decisión sobre los ejemplos 2 y 3. Visualiza el resultado y coméntalo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí para el ejemplo 2\n",
    "\n",
    "data2 = ...\n",
    "X2 = ...\n",
    "y2 = ...\n",
    "\n",
    "treeModel2 = ...\n",
    "\n",
    "plot_decision_boundary(X2, y2, treeModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí para el ejemplo 3\n",
    "treeModel3 = ...\n",
    "plot_decision_boundary(X3, y3, treeModel3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vista de los ejemplos anteriores, podemos comprobar varias cosas:\n",
    "\n",
    "1) Seguramente estamos cometiendo overfitting, porque las fronteras de separación son altamente complejas, ¿cómo podemos controlar la complejidad de un árbol?\n",
    "\n",
    "2) Las prestaciones las estamos midiendo sobre el conjunto de entrenamiento, por lo que no sabemos el alcance real que tienen estos algoritmos.\n",
    "\n",
    "Vayamos por partes. Sobre 1)\n",
    "\n",
    "\n",
    "Los árboles de decisión tienen varios parámetros para controlar la complejidad del mismo (véase la [documentación](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)). Normalmente, los parámetros más relevantes para controlar la complejidad son:\n",
    "\n",
    "* **profundidad** del árbol (*max_depth*): Si utilizamos un árbol de profundidad 1, sólo podremos dividir el espacio en dos (una decisión). Si utilizamos un árbol de profundidad 2, dividiremos en 4 secciones, y así sucesivamente. Por tanto, con la profundidad controlamos la complejidad del árbol de decisión, y este parámetro sirve como herramienta para **regularizar* el algoritmo:\n",
    "\n",
    "    - Un árbol de poca profundidad (poco complejo), tendrá menor riesgo de sufrir overfitting a costa de, potencialmente, incurrir en más error de clasificación.\n",
    "\n",
    "    - Un árbol de mucha profundidad (muy complejo), tendrá mayor riesgo de sufrir overfitting a costa de, potencialmente, mejorar el error de clasificación.\n",
    "\n",
    "* **Número mínimo de muestras en una hoja** (*min_samples_leaf*). Podemos forzar a que una hoja tenga un número mínimo de muestras en cada hoja, de tal forma que:\n",
    "    - Un árbol con un *min_samples_leaf* elevado, tendrá complejidad menor que un árbol con *min_samples_leaf* pequeño.\n",
    "    \n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 4.2: Varía los parámetros <b>max_depth</b> y <b>min_samples_leaf</b> (de forma independiente y después conjuntamente) y comprueba el resultado, ¿coincide con tu intuición?\n",
    "</div>\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 4.3: Calcule el valor óptimo de <b>max_depth</b> para el ejemplo 3, ¿cuáles son las prestaciones del algoritmo para este ejemplo?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... código aquí\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "max_depth_vector = list(range(1, 20))\n",
    "param_grid = {'max_depth': max_depth_vector}\n",
    "# ... código aquí\n",
    "grid = ...\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.plot(max_depth_vector,scores,'-o')\n",
    "plt.xlabel('max depth [Complejidad del modelo]',fontsize=16)\n",
    "plt.ylabel('10-Fold Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Árboles de clasificación sobre ejemplo realista\n",
    "\n",
    "Vamos a trabajar sobre un **problema multiclase** de clasificación de frutas a partir de sus propiedades. También abordaremos la visualización de un árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = pd.read_table('./data/fruit_data_with_colors.txt')\n",
    "print(fruits.shape)\n",
    "\n",
    "fruits.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto se puede hacer con un label encoder\n",
    "lookup_fruit_name = dict(zip(fruits.fruit_label.unique(), fruits.fruit_name.unique()))   \n",
    "lookup_fruit_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# preparamos los datos\n",
    "X = fruits[['height', 'width', 'mass', 'color_score']].values\n",
    "y = fruits['fruit_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "print('Datos train: ', X_train.shape)\n",
    "print('Datos test:  ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# creamos el modelo y ajustamos\n",
    "treeModel = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_test_predicted = treeModel.predict(X_test)\n",
    "print(treeModel.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores óptimos de max_depth (por ejemplo) habría que sacarlos con validación cruzada. Este dataset es extremadamente pequeño, con lo cual vamos a probar validación cruzada con estrategia leave-one-out.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 4.4: Calcule el valor óptimo de <b>max_depth</b> con y sin estrategia leave-one-out\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_vector = list(range(1, 20))\n",
    "param_grid = {'max_depth': max_depth_vector}\n",
    "# ... código aquí\n",
    "grid = ...\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.plot(max_depth_vector,scores,'-o')\n",
    "plt.xlabel('max depth [Complejidad del modelo]',fontsize=16)\n",
    "plt.ylabel('10-Fold Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "max_depth_vector = list(range(1, 6))\n",
    "param_grid = {'max_depth': max_depth_vector }\n",
    "# ... código aquí\n",
    "grid = ...\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.plot(max_depth_vector,scores,'-o')\n",
    "plt.xlabel('max depth [Complejidad del modelo]',fontsize=16)\n",
    "plt.ylabel('10-Fold Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo visualizar un árbol?\n",
    "\n",
    "Hay varias formas de representar un árbol. Se puede pintar una representación textual; algo similar al comando `tree` de Unix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "text_representation = tree.export_text(treeModel)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero es mucho más completo y potente e intuitivo representar el árbol como un árbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(treeModel, \n",
    "                   feature_names=['height', 'width', 'mass', 'color_score'],  \n",
    "                    class_names=['apple','mandarin','orange','lemon'],\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vista de la figura, observamos que:\n",
    "\n",
    "1) Comenzamos con un Gini elevado ¿cuál es el máximo valor para este problema? y a medida que aumentamos la profundidad el valor Gini diminuye, hasta que en todas las hojas es 0.\n",
    "\n",
    "2) Es un árbol de profundidad 4.\n",
    "\n",
    "3) Todas las muestras de entrenamiento están bien clasificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['height', 'width', 'mass', 'color_score']\n",
    "test_sample = 2\n",
    "\n",
    "print('La muestra de test con etiqueta \"{0}\" y atributos: '.format(lookup_fruit_name[y_test[test_sample]]))\n",
    "for i,f in enumerate(features):\n",
    "    print(' ',f,':',X_test[test_sample,i])\n",
    "\n",
    "print(\"ha sido clasificada como: '{0}' \".format(lookup_fruit_name[y_test_predicted[test_sample]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 4.5: Para el ejemplo de la celda anterior, ¿puedes seguir el camino de la decisión?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Árboles de regresión\n",
    "\n",
    "Vamos a aplicar árboles de regresión sobre nuestro ejemplo de regresión sintético:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 10\n",
    "N_test  = 100\n",
    "\n",
    "# función verdadera g(x)\n",
    "x = np.linspace(0,1,N_test)\n",
    "g_x = np.cos(1.5*np.pi*x)\n",
    "\n",
    "# proceso y\n",
    "np.random.seed(0) # para asegurar reproducibilidad\n",
    "epsilon = np.random.randn(N_test) * 0.2\n",
    "y = g_x + epsilon\n",
    "\n",
    "# Datos: D = {x_i,y_i}, obtenemos una muestra\n",
    "idx = np.random.randint(0,N_test,N_train)\n",
    "x_i = x[idx]\n",
    "y_i = y[idx]\n",
    "\n",
    "plt.plot(x,g_x,'r',label='y')\n",
    "plt.plot(x_i,y_i,'b.',label='Training set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 4.6: Entrena un árbol de decisión sobre estos datos\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_train = x_i.reshape(-1, 1)\n",
    "y_train = y_i\n",
    "X_test  = x.reshape(-1, 1)\n",
    "\n",
    "# ... código aquí\n",
    "regTree = ...\n",
    "\n",
    "y_hat = regTree.predict(X_test)\n",
    "\n",
    "# error\n",
    "error_test = np.mean(np.power(y - y_hat,2)) \n",
    "\n",
    "\n",
    "plt.plot(x,g_x,'r',label='$y$')\n",
    "plt.plot(x_i,y_i,'b.',label='$y_i$')\n",
    "plt.plot(x,y_hat,'g',label='$\\hat{y}$')\n",
    "plt.title('MSE:%.2f'%error_test)\n",
    "plt.legend()\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 4.7: Modifica los valores de <b>max_depth</b> y observa el resultado, ¿concuerda con tu intuición?\n",
    "</div>\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 4.8: Representa el árbol entrenado\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "# ... código aquí\n",
    "_ = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
