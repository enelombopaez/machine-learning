{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas\n",
    "\n",
    "En este Notebook vamos analizar distintas métricas y algoritmos sobre un problema de clasificación desbalanceado. Ya hemos visto las principales métricas de regresión (MSE y RMSE) así que no nos detendremos en ellas aquí.\n",
    "\n",
    "1. Análisis exploratorio\n",
    "2. Métricas clasificación\n",
    "3. Comparación clasificadores\n",
    "\n",
    "Lo primero es cargar las librerías y funciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_confusion_matrix, CM_BRIGHT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para calcular y representar las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_metricas(confmat):\n",
    "    \n",
    "    tn, fp, fn, tp = confmat.ravel()\n",
    "\n",
    "    acc = (tp+tn)/(tn + fp + fn + tp)\n",
    "    sen = tp/(tp+fn)\n",
    "    esp = tn/(tn+fp)\n",
    "    ppv = tp/(tp+fp)\n",
    "    fsc = 2*(sen*ppv/(sen+ppv))\n",
    "\n",
    "    print('ACC: ', acc)\n",
    "    print('SEN: ', sen)\n",
    "    print('ESP: ', esp)\n",
    "    print('PPV: ', ppv)\n",
    "    print('FSC: ', fsc)\n",
    "    \n",
    "    plt.bar(range(5),[acc,sen,esp,ppv,fsc])\n",
    "    plt.xticks(range(5),['ACC','SEN','ESP','PPV','FSC'])\n",
    "    plt.plot([-1, 6], [1, 1], color=(0.6, 0.6, 0.6), linestyle='--')\n",
    "    plt.xlim((-0.5,4.5))\n",
    "    plt.ylim((0,1.1))\n",
    "    plt.title('Metricas')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. División train/test\n",
    "\n",
    "Esta vez vamos a hacer las cosas bien hechas y dividiremos antes de hacer ningún tipo de análisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_df = pd.read_csv('data/churn.csv', sep=',')\n",
    "train, test = train_test_split(full_df, test_size=0.2, shuffle=True, stratify=full_df['churn'], random_state=0)\n",
    "\n",
    "print(f'Dimensiones del dataset de training: {train.shape}')\n",
    "print(f'Dimensiones del dataset de test: {test.shape}')\n",
    "\n",
    "# Guardamos\n",
    "train.to_csv('./data/churn_train.csv', sep=',', index=False)\n",
    "test.to_csv('./data/churn_test.csv', sep=',', index=False)\n",
    "\n",
    "# A partir de este momento cargamos el dataset de train y trabajamos ÚNICAMENTE con él. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Análisis exploratorio\n",
    "\n",
    "Vamos a trabajar con datos de fuga de una compañía telefónica. El objetivo es predecir si los clientes van a abandonar la compañía.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.1: Carga los datos *churn_train.csv* y realiza un primer análisis.\n",
    "</div>\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.2: Este problema está desbalanceado; calcula el ratio de desbalanceo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí: carga de datos\n",
    "data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí: desbalanceo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.1 Preprocesamiento de variables\n",
    "\n",
    "Si escribimos *data.dtypes* nos indica el tipo de las variables de nuestro dataframe. Vemos que tenemos variables categóricas que tenemos que codificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.3: Elimine la variable *phone number* y codifique las variables categóricas con un Label Encoder.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí: elimina phone number\n",
    "data = data.drop(['phone number'], axis=1)\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí: codificación\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_state = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.4: Represente el histograma de las variable con distintos colores para cada clase.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí: histogramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Correlación entre variables\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.5: Representa el mapa de correlación entre variables.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# ... código aquí: correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos pintar las variables más correlacionadas (>0.95) con un scatter plot, para ver qué tipo de relación tienen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = data.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "threshold = 0.95\n",
    "pairs = np.where(upper>threshold)\n",
    "fx = data.columns[pairs[0]]\n",
    "fy =  data.columns[pairs[1]]\n",
    "\n",
    "i=1\n",
    "plt.figure(figsize=(22,4))\n",
    "for f1,f2 in zip(fx,fy):\n",
    "    \n",
    "    plt.subplot(1,5,i)\n",
    "    \n",
    "    plt.scatter(data[f1],data[f2], c=data['churn'],cmap=CM_BRIGHT, alpha=0.25)\n",
    "    plt.xlabel(f1)\n",
    "    plt.ylabel(f2)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la correlación extrema y con el objetivo de eliminar variables poco informativas, podemos eliminar algunas columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['total day minutes', 'total eve minutes', 'total night minutes', 'total intl minutes']\n",
    "data = data.drop(columns_to_drop, axis=1)\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es buena idea agrupar todo el análisis y preprocesamiento en una única celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESUMO MI ANÁLISIS COMPLETO\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_csv('data/churn_train.csv', sep=',')\n",
    "\n",
    "# Elimino phone number\n",
    "data = data.drop(['phone number'], axis=1)\n",
    "\n",
    "# Codifico las variables categóricas\n",
    "le_state = LabelEncoder()\n",
    "le_ip = LabelEncoder()\n",
    "le_vmp = LabelEncoder()\n",
    "le_churn = LabelEncoder()\n",
    "\n",
    "data['state'] = le_state.fit_transform(data['state'])\n",
    "data['international plan'] = le_ip.fit_transform(data['international plan'])\n",
    "data['voice mail plan'] = le_vmp.fit_transform(data['voice mail plan'])\n",
    "data['churn'] = le_churn.fit_transform(data['churn'])\n",
    "\n",
    "# Elimino columnas muy correlacionadas\n",
    "columns_to_drop = ['total day minutes','total eve minutes','total night minutes','total intl minutes']\n",
    "data = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porque así puedo aplicarlo muy fácilmente a test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data/churn_test.csv', sep=',')\n",
    "\n",
    "# Elimino phone number\n",
    "data_test = data_test.drop(['phone number'], axis=1)\n",
    "\n",
    "# Codifico las variables categóricas\n",
    "# con los mismos LabelEncoder de train, porque quiero conservar las clases\n",
    "\n",
    "# data_test['state'].apply(x: x = 'Unknown' if x not in le_state.classes_)\n",
    "\n",
    "data_test['state'] = le_state.transform(data_test['state'])\n",
    "data_test['international plan'] = le_ip.transform(data_test['international plan'])\n",
    "data_test['voice mail plan'] = le_vmp.transform(data_test['voice mail plan'])\n",
    "data_test['churn'] = le_churn.transform(data_test['churn'])\n",
    "\n",
    "# Elimino columnas muy correlacionadas\n",
    "columns_to_drop = ['total day minutes','total eve minutes','total night minutes','total intl minutes']\n",
    "data_test = data_test.drop(columns_to_drop, axis=1)\n",
    "\n",
    "print(data_test.shape)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Métricas en clasificación\n",
    "\n",
    "Vamos a representar la matriz de confusión, y a partir de ella calcular distintas métricas. Para ello, comencemos un clasificador sencillo: regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# preparamos los datos, un pelín distinto de otras veces\n",
    "features = data.drop(['churn'], axis=1).columns\n",
    "\n",
    "X_train = data[features].values\n",
    "y_train = data['churn'].values\n",
    "\n",
    "X_test = data_test[features].values\n",
    "y_test = data_test['churn'].values\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xs_train = scaler.transform(X_train)\n",
    "Xs_test  = scaler.transform(X_test)\n",
    "\n",
    "print('Datos train: ', Xs_train.shape)\n",
    "print('Datos test:  ', Xs_test.shape)\n",
    "\n",
    "print('Proporcion train:%0.3f'%np.mean(y_train))\n",
    "print('Proporcion test: %0.3f'%np.mean(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Matriz de confusión y métricas\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.6: Ajuste un algoritmo de regresión logística sobre el conjunto de entrenamiento con $C = 1$. Calcule la predicción para el conjunto de entrenamiento (*y_pred*).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ... código aquí\n",
    "lr = ...\n",
    "y_pred = lr.predict(Xs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confmat = confusion_matrix(y_train,y_pred)\n",
    "plot_confusion_matrix(confmat)\n",
    "\n",
    "# Podemos acceder a los valores de la matriz\n",
    "tn, fp, fn, tp = confusion_matrix(y_train,y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcula_metricas(confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.7: Calcule la predicción para el conjunto de test (*y_pred_test*).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = ...\n",
    "\n",
    "confmat = confusion_matrix(y_test,y_pred_test)\n",
    "plot_confusion_matrix(confmat)\n",
    "calcula_metricas(confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora representamos de nuevo los histogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = lr.predict_proba(Xs_test)[:,1]\n",
    "\n",
    "idx_0 = (y_test==0)\n",
    "idx_1 = (y_test==1)\n",
    "\n",
    "plt.hist(y_prob[idx_0],density=1, alpha=0.75,label='y=0')\n",
    "plt.hist(y_prob[idx_1],density=1, facecolor='red', alpha=0.75,label='y=1')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a representar la curva ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "ejex, ejey, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(ejex, ejey)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ejex, ejey, color='darkorange',lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=(0.6, 0.6, 0.6), linestyle='--')\n",
    "plt.plot([0, 0, 1],[0, 1, 1],lw=2, linestyle=':',color='black',label='Clasificador perfecto')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "plt.xlabel('FPR (1-ESP)')\n",
    "plt.ylabel('SEN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Comparación clasificadores\n",
    "\n",
    "Vamos a comparar los siguientes clasificadores: \n",
    "\n",
    "* Regresión logística\n",
    "* Árboles de decisión\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.1 Regresión logística\n",
    "\n",
    "Hemos visto que este algoritmo está sesgado hacia la clase mayoritoria. Para compensar esta situación, podemos asignar pesos distintos a los errores cometidos en cada una de las clases, a través del parámetro [*class_weight*](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "Además, podemos trabajar con distintas [métricas](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) a la hora de optimizar los parámetros libres. Para conjuntos desbalancedados es adecuada 'f1': F1-score, compromiso entre SEN y PPV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vectorC = np.logspace(-3,3,21)\n",
    "param_grid = {'C': vectorC }\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(random_state=0, class_weight='balanced'),\n",
    "                    scoring='accuracy', \n",
    "                    param_grid=param_grid, \n",
    "                    cv = 10)\n",
    "\n",
    "grid.fit(Xs_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = grid.cv_results_['mean_test_score']\n",
    "std_scores = grid.cv_results_['std_test_score']\n",
    "plt.errorbar(np.log10(vectorC),scores,yerr=std_scores, fmt='o-',ecolor='g')\n",
    "plt.xlabel('log(C)',fontsize=16)\n",
    "plt.ylabel('10-Fold MSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.8: El código de arriba optimiza balanceado y con accuracy. Compare el resultado con respecto a entrenar tres combinaciones: sin balancear + accuracy; sin balancear + F1; balanceado + F1.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...código aquí: not balanced + ACC\n",
    "grid = ...\n",
    "Copt = grid.best_params_['C']\n",
    "\n",
    "lr = ...\n",
    "y_pred = lr.predict(Xs_test)\n",
    "\n",
    "confmat_test  = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(confmat_test)\n",
    "calcula_metricas(confmat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...código aquí: not balanced + F1\n",
    "grid = ...\n",
    "Copt = grid.best_params_['C']\n",
    "\n",
    "lr = ...\n",
    "y_pred = lr.predict(Xs_test)\n",
    "\n",
    "confmat_test  = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(confmat_test)\n",
    "calcula_metricas(confmat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...código aquí: balanced + F1\n",
    "grid = ...\n",
    "Copt = grid.best_params_['C']\n",
    "\n",
    "lr = ...\n",
    "y_pred = lr.predict(Xs_test)\n",
    "\n",
    "confmat_test  = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(confmat_test)\n",
    "calcula_metricas(confmat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a representar histogramas para esta última:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = lr.predict_proba(Xs_test)[:,1]\n",
    "\n",
    "idx_0 = (y_test==0)\n",
    "idx_1 = (y_test==1)\n",
    "\n",
    "plt.hist(y_prob[idx_0],density=1, alpha=0.75,label='y=0')\n",
    "plt.hist(y_prob[idx_1],density=1, facecolor='red', alpha=0.75,label='y=1')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "ejex, ejey, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(ejex, ejey)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ejex, ejey, color='darkorange',lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=(0.6, 0.6, 0.6), linestyle='--')\n",
    "plt.plot([0, 0, 1],[0, 1, 1],lw=2, linestyle=':',color='black',label='Clasificador perfecto')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "plt.xlabel('FPR (1-ESP)')\n",
    "plt.ylabel('SEN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Árboles de decisión\n",
    "\n",
    "Entrenamos ahora un árbol de decisión. Otra ventaja adicional de los árboles es que por su construcción hace frente al desbalanceo de las clases.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.9: Entrena un árbol de decisión y calcula las métricas obtenidas en el conjunto de test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "maxDepth = range(1,15)\n",
    "param_grid = {'max_depth': maxDepth }\n",
    "\n",
    "# ... código aquí\n",
    "grid = ...\n",
    "grid.fit(Xs_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.plot(maxDepth,scores,'-o')\n",
    "plt.xlabel('max_depth',fontsize=16)\n",
    "plt.ylabel('10-Fold MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepthOptimo = grid.best_params_['max_depth']\n",
    "# ... código aquí\n",
    "treeModel = ...\n",
    "\n",
    "print(\"Train: \",treeModel.score(Xs_train,y_train))\n",
    "# fun fact: me equivoqué al copiar y dejé X_test. Haced la prueba, a ver qué pasa.\n",
    "print(\"Test: \",treeModel.score(Xs_test,y_test)) \n",
    "\n",
    "y_pred = treeModel.predict(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí\n",
    "confmat_test = ...\n",
    "plot_confusion_matrix(confmat_test)\n",
    "calcula_metricas(confmat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es un árbol individual, podemos representarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(treeModel, feature_names=list(features), filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Random Forest\n",
    "\n",
    "Comprobemos prestaciones para un algoritmo de Random Forest.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 8.10: Entrena un algoritmo de Random Forest y calcula las métricas obtenidas en el conjunto de test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# grid search\n",
    "maxDepth   = range(1,15)\n",
    "param_grid = {'max_depth': maxDepth}\n",
    "\n",
    "# ... código aquí\n",
    "grid = ...\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.plot(maxDepth,scores,'-o')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('10-fold ACC')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepthOptimo = grid.best_params_['max_depth']\n",
    "# ... código aquí\n",
    "rf = ...\n",
    "\n",
    "print(\"Train: \",rf.score(Xs_train,y_train))\n",
    "print(\"Test: \",rf.score(Xs_test,y_test)) \n",
    "\n",
    "y_pred = rf.predict(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí\n",
    "confmat_test = ...\n",
    "plot_confusion_matrix(confmat_test)\n",
    "calcula_metricas(confmat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podríais evaluar cualquier algoritmo de sklearn, no sólo los que hemos visto en clase. Simplemente encontrad el (o los) parámetro que regula la complejidad, y ajustadlo con validación cruzada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
